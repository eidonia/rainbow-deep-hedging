{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport scipy.stats as stats",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class EuropeanRainbow:\n    \n    def __init__(self):\n        \n        pass\n    \n    def get_Stulz_price(self, S = None, cov = None, r = None, K = None, matu = None, N = None, nbPaths = None):\n        \n        dt = matu / N\n        T = np.arange(0,N) * dt\n        T = np.repeat(np.flip(T[None,:]), S.shape[0], axis=0)\n        \n        spot1 = np.zeros((nbPaths,N))\n        spot2 = np.zeros((nbPaths,N))\n        \n        eta1 = np.zeros((nbPaths,N))\n        eta2 = np.zeros((nbPaths,N))\n        \n        beta1 = np.zeros((nbPaths,N))\n        beta2 = np.zeros((nbPaths,N))\n        \n        gamma1 = np.zeros((nbPaths,N))\n        gamma2 = np.zeros((nbPaths,N))\n        \n        spot1[:,:] = S[:,:,0]\n        spot2[:,:] = S[:,:,1]\n        \n        sigma1 = np.sqrt(cov[0,0])\n        sigma2 = np.sqrt(cov[1,1])\n        rho = cov[0,1]/(sigma1*sigma2)\n        \n        sig = sigma1**2 + sigma2**2 + 2*rho*sigma1*sigma2\n        rho_indiv1 = (rho*sigma2 - sigma1) / sig\n        rho_indiv2 = (rho*sigma1 - sigma2) / sig\n        \n        with np.errstate(divide=\"ignore\"):\n            eta1 = np.divide(np.log(spot1/K)+(r+0.5*sigma1**2)*T, (sigma1*np.sqrt(T)))\n            eta2 = np.divide(np.log(spot2/K)+(r-0.5*sigma2**2)*T, (sigma2*np.sqrt(T)))\n            \n            beta1 = np.divide(np.log(spot1/spot2)-0.5*(sig**2*np.sqrt(T)),sig*np.sqrt(T))\n            beta2 = np.divide(np.log(spot2/spot1)-0.5*(sig**2*np.sqrt(T)),sig*np.sqrt(T))\n            \n            gamma1 = eta1 - sigma1*np.sqrt(T)\n            gamma2 = eta2 - sigma2*np.sqrt(T)\n            \n        price = spot1 * np.random.multivariate_normal((eta1[0,0],beta1[0,0]),rho_indiv1)\n        \n        return price\n\nm=np.array([0.1,0.2])\nspot_init=np.array([100,100])\nT=1\nN=30\ncov=np.array([[0.1,0.05],[0.05,0.1]])\nprob1=0.2\nprob2=0.2\nr=0.0\nK=100\nmatu=1\nnbPaths=1\n\ntest = multiJumpDiffusion(m=m, spot_init=spot_init, T=T, N=N, cov=cov, prob1=prob1, prob2=prob2)\nS = test.gen_path(nbPaths=nbPaths)\n\nrainbow = EuropeanRainbow()\nspot_divide = rainbow.get_Stulz_price(S=S,cov=cov,r=r,K=K,matu=matu,N=N,nbPaths=nbPaths)\n# so far I managed to code something that separates well the dynamics of the two underlying assets!\n\nprint(spot_divide)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 69,
      "outputs": [
        {
          "ename": "<class 'ValueError'>",
          "evalue": "cov must be 2 dimensional and square",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m S \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mgen_path(nbPaths\u001b[38;5;241m=\u001b[39mnbPaths)\n\u001b[1;32m     65\u001b[0m rainbow \u001b[38;5;241m=\u001b[39m EuropeanRainbow()\n\u001b[0;32m---> 66\u001b[0m spot_divide \u001b[38;5;241m=\u001b[39m \u001b[43mrainbow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_Stulz_price\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcov\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmatu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatu\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnbPaths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnbPaths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# so far I managed to code something that separates well the dynamics of the two underlying assets!\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(spot_divide)\n",
            "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36mEuropeanRainbow.get_Stulz_price\u001b[0;34m(self, S, cov, r, K, matu, N, nbPaths)\u001b[0m\n\u001b[1;32m     43\u001b[0m     gamma1 \u001b[38;5;241m=\u001b[39m eta1 \u001b[38;5;241m-\u001b[39m sigma1\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(T)\n\u001b[1;32m     44\u001b[0m     gamma2 \u001b[38;5;241m=\u001b[39m eta2 \u001b[38;5;241m-\u001b[39m sigma2\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(T)\n\u001b[0;32m---> 46\u001b[0m price \u001b[38;5;241m=\u001b[39m spot1 \u001b[38;5;241m*\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43meta1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrho_indiv1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m price\n",
            "File \u001b[0;32mmtrand.pyx:4092\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cov must be 2 dimensional and square"
          ],
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# multi-asset jump diffusion model\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass multiJumpDiffusion:\n    \n    def __init__(self, m = None, spot_init = None, T = None, N = None, cov = None, prob1 = None, prob2 = None):\n        \n        self.m = m\n        self.spot_init = spot_init\n        self.T = T\n        self.N = N\n        self.cov = cov\n        self.prob1 = prob1\n        self.prob2 = prob2\n        \n    def gen_process(self):\n        \n        dt = self.T / self.N\n        sigma = np.zeros(2)\n        processes = np.zeros((self.N, 2))\n        processes[0,:] = np.log(self.spot_init)\n        \n        drift = np.zeros(2)\n        diffusion = np.zeros(2)\n        \n        for i in range(1, self.N):\n            \n            z1 = np.random.normal(0,1)\n            sigma[0] = np.sqrt(cov[0,0])\n            sigma[1] = np.sqrt(cov[1,1])\n            \n            drift = 0.5 * (sigma ** 2) * dt\n            diffusion = np.sqrt(self.T / self.N) * np.matmul(np.linalg.cholesky(self.cov), np.random.normal(0,1,size=2))\n            jump = self.gen_jump(sigma[0], sigma[1])\n            \n            processes[i,:] = processes[i-1,:] - drift + diffusion + jump\n            \n        return np.exp(processes)\n    \n    def gen_jump(self, sigma1 = None, sigma2 = None):\n        \n        jump = np.zeros(2)\n        a1 = np.zeros(2)\n        a2 = np.zeros(2)\n        a3 = np.zeros(2)\n        zero = np.zeros(2)\n        \n        a1[:] = 0\n        a2[:] = 0\n        a3[:] = 0\n        \n        z=np.zeros(3)\n        z[0] = 1\n        z[1] = 2\n        z[2] = 3\n        \n        val = np.random.choice(z,1,p=[1 - self.prob1 - self.prob2, self.prob1, self.prob2])\n        \n        if val == 1:\n            jump = (self.m*np.random.exponential()+np.sqrt(np.random.exponential())*np.random.multivariate_normal(zero,self.cov))\n        elif val == 2:\n            jump = [sigma1*np.random.exponential()+np.sqrt(np.random.exponential())*np.random.normal(0,sigma1**2),0]\n        elif val == 3:\n            jump = [0,sigma2*np.random.exponential()+np.sqrt(np.random.exponential())*np.random.normal(0,sigma2**2)]\n        \n        return np.random.poisson(1*self.T/self.N,size=2)*jump\n    \n    def gen_path(self, nbPaths = None):\n        \n        dt = np.divide(self.T,self.N)\n        dualPaths = np.zeros(((nbPaths,self.N,2)))\n        \n        for i in range(nbPaths):\n            dualPaths[i,:,:] = self.gen_process()\n        \n        return dualPaths\n    \nm=np.array([0.1,0.2])\nspot_init=np.array([100,100])\nT=1\nN=30\ncov=np.array([[0.1,0.05],[0.05,0.1]])\nprob1=0.2\nprob2=0.2\n    \ntest = multiJumpDiffusion(m=m, spot_init=spot_init, T=T, N=N, cov=cov, prob1=prob1, prob2=prob2)\nhihi = test.gen_path(3)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport numpy as np\n\nfrom math import log, sqrt, exp, pi",
      "metadata": {
        "trusted": true
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# looks like a cdf implementation: https://github.com/stan-dev/stan/issues/2356\n# looks like it is talked about in more details here: https://github.com/tensorflow/probability/issues/422\n\n# bon apparement on peut le faire en matlab mdr: https://fr.mathworks.com/matlabcentral/fileexchange/7025-bivariate-cumulative-normal-probability\n# c'est déjà ça\n\n# voila une implémentation python à étudier: https://github.com/wanglouis49/risk_estimation/blob/master/blspricer.py\n# autre github qui traite de cette fonction: https://github.com/nuance/python-nlp/blob/master/nlp/lib/mvncdf.py\n# mmmmh intéressant! - http://www-2.rotman.utoronto.ca/~hull/TechnicalNotes/TechnicalNote5.pdf",
      "metadata": {
        "trusted": true
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def bivnormcdf(a,b,rho):\n\n\tif a <= 0. and b <= 0. and rho <= 0. :\n\t\taprime = a/sqrt(2.*(1.-rho**2.))\n\t\tbprime = b/sqrt(2.*(1.-rho**2.))\n\t\tA = np.array([0.3253030, 0.4211071, 0.1334425, 0.006374323])\n\t\tB = np.array([0.1337764, 0.6243247, 1.3425378, 2.2626645])\n\n\t\tt = 0.\n\n\t\tfor i in range(4):\n\t\t\tfor j in range(4):\n\t\t\t\tx = B[i]\n\t\t\t\ty = B[j]\n\t\t\t\tt += A[i]*A[j]* exp(aprime*(2.*x - aprime) \\\n\t\t\t\t     + (bprime*(2.*y - bprime)) + (2.*rho * (x - aprime)*(y-bprime)))\n\n\t\tp = (sqrt(1.-rho**2.)/pi) * t\n\n\telif a * b * rho <= 0. :\n\t\tif a <= 0. and b >= 0. and rho >= 0. :\n\t\t\tp = stats.norm.cdf(a) - bivnormcdf(a,-b,-rho)\n\t\telif a >= 0. and b <= 0. and rho >= 0. :\n\t\t\tp = stats.norm.cdf(b) - bivnormcdf(-a,b,-rho)\n\t\telif a >= 0. and b >= 0. and rho <= 0. :\n\t\t\tp = stats.norm.cdf(a) + stats.norm.cdf(b) - 1. + bivnormcdf(-a,-b,rho)\n\n\telif a*b*rho > 0. :\n\t\tif a >= 0. :\n\t\t\tasign = 1.\n\t\telse:\n\t\t\tasign = -1.\n\n\t\tif b >= 0.:\n\t\t\tbsign = 1.\n\t\telse:\n\t\t\tbsign = -1.\n\n\t\trho1 = (rho*a - b)*asign/(sqrt(a**2. - (2.*rho*a*b) + b**2.))\n\t\trho2 = (rho*b - a)*bsign/(sqrt(a**2. - (2.*rho*a*b) + b**2.))\n\t\tdelta = (1. - (asign*bsign))/4.\n\n\t\tp = bivnormcdf(a,0,rho1) + bivnormcdf(b,0,rho2) - delta\n\treturn p\n\na = bivnormcdf(0,0,0.99)\nprint(a)\n\n# on se base sur le papier de Hull\n# je pense que ce soir on peut essayer d'implémenter tout ça sur notre gros code Python\n# puis implémenter tout ça (concisement bien sur) dans notre papier\n# essayer de refaire tourner notre algo de vanille et tenter de trouver le pb (pk il marche pas)\n# continuer à candidater à plein de stages (et bien tenir le excel avec l'historique des candidatures)\n\n# faut absolument qu'on ait un code final parfait et très très bien structuré!!",
      "metadata": {
        "trusted": true
      },
      "execution_count": 93,
      "outputs": [
        {
          "name": "stdout",
          "text": "0.4774746939518141\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# résumé de l'avancé de la journée\n\n# très légères recherches sur les signaux de trading liés à la volat et à la correl (besoin de mieux structurer tout ça)\n# on a bien avancer sur le multi-JD (je pense qu'il est carré), et je pense donc que toutes nos dynamiques sont plus ou moins bonnes\n# on a plutot avancé sur la classe des Rainbows, on y voit plus clair\n# on a réussi à séparer le set initial de deux spots en deux sets d'un spot (utile pour la classe Rainbow)\n# on a ENFIN trouvé comment calculer dans Python la proba bivariate std normale, qui nous sera ultra utile pour tout!\n\n# plan de la poursuite du travail de ce soir (hors candidatures pour stages)\n\n# implémentation très très propre de tous nos ajouts dans le gros dossier de coode sur PyCharm\n# on tente de continuer la classe des Rainbow (au moins le prix et le delta de l'option) + on s'assure que c'est pas aberrant\n# on vérifie que l'implémentation de toutes les dynamiques nous fournit des résultats cohérents, pour pouvoir avoir bouclé cte partie\n# on implémente nos changements par écrit dans le papier (de manière propre) et on fait qq modifs de clarté dans le chap5\n# refaire tourner un peu notre algo et tenter de comprendre pk les résultats sont bizarres pour la stratégie de deep hedge\n\n# plan de candidatures aux stages de ce soir\n\n# minimum de cinq belles candidatures (on tente huit)\n# on y va à fond!",
      "metadata": {
        "trusted": true
      },
      "execution_count": 96,
      "outputs": []
    }
  ]
}