{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# ----------------------------------------------------------------------------\n# we lay out the structure of the deep learning algorithm that we are building\n# ----------------------------------------------------------------------------\n\n# ------------------------------ part 1 --------------------------------------\n# we import the main software libraries\n# numpy - tensorflow - scipy.stats - matplotlib.pyplot - IPython.display\n\n# we initialize all our input parameters\n# N - spot_init - r - k_train - k_test_ratio - strike - T - eps - info_set\n# loss_type - loss_param - nbNeurons - nbHidden - learningRate - batch_size - epochs\n# use_batch_norm - kernel_initializer - activ_func_dense - activ_func_output - cost_T\n# share_strategy_across_time - seed\n\n# we compute other parameters\n# nbObs - dt\n# ----------------------------------------------------------------------------\n\n# ------------------------------ part 2 --------------------------------------\n# we generate our stochastic process\n# by first calling the class, and then the path function inside the class (to generate multiple)\n# ----------------------------------------------------------------------------\n\n# ------------------------------ part 3 --------------------------------------\n# we prepare the data\n# filling the payoff_final set -> will need to be adapted for the put and the rainbow\n# filling the trading set -> all spot moves stacked\n# filling the info set -> log-normalized spot returns\n\n# we fill everything into x_all\n\n# we prepare the x_train and x_test set\n# we do that by splitting x_all\n# ----------------------------------------------------------------------------\n\n# ------------------------------ part 4 --------------------------------------\n# we setup the model -> calling the \"hedging\" function\n# we define and append the loss function to the model\n# we compile the model using \"adam\"\n# we fit the model\n# (notice that we can do all that either by using the simple or the recurrent model)\n# ----------------------------------------------------------------------------\n\n# ------------------------------ part 5 --------------------------------------\n# we retrieve price + delta + PnL from BlackScholes, of the option\n# we compare the Black-Scholes and Deep-Hedging PnL\n# ----------------------------------------------------------------------------\n\n\n# ------------------------------ questions I still have ----------------------\n# I really dont understand what the algorithm is trying to minimize or maximize\n# at no point do we give him the PnL or the \"resulting cash injection\" that it must optimize\n# still need to make some more research to adapt the strategy to two assets\n# but as far as I see it, the adjustment appears doable!\n\n# we will compare PnL and losses (we dont care about the strategy per se, just their result)\n# what we still need to do: class module for the rainbow option (price + delta + PnL)\n# make sure that the jump-diffusion model works properly\n# try coding more loss functions (MSE ?)\n# need to dive deeper into the deep learning part of the algo\n# so that we can modify it ourselves + adapt it for two underlyings\n# ----------------------------------------------------------------------------\n\n# avancement dans la compréhension\n# notre algo de DL compute une fonction de wealth (classique, on la connait)\n# et après on fit une fonction de perte (ici l'entropy)\n# où on cherche à minimiser la fonction de perte avec la wealth en argument ?\n# alors que l'idée de base c'est de trouver la stratégie (donc delta) tel que cette perte soit min",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}